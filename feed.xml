<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://bobb1ranger.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://bobb1ranger.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2026-01-12T20:06:58+00:00</updated><id>https://bobb1ranger.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Reinforcement Learning Tech Tree</title><link href="https://bobb1ranger.github.io/blog/2026/Reinforcement-Learning-TechTree/" rel="alternate" type="text/html" title="Reinforcement Learning Tech Tree"/><published>2026-01-12T02:09:00+00:00</published><updated>2026-01-12T02:09:00+00:00</updated><id>https://bobb1ranger.github.io/blog/2026/Reinforcement-Learning-TechTree</id><content type="html" xml:base="https://bobb1ranger.github.io/blog/2026/Reinforcement-Learning-TechTree/"><![CDATA[<p><a href="/assets/html/rl_tech_tree.html">View the interactive RL Tech Tree</a></p> <p>I’ll keep updating this as I learn more about reinforcement learning and its various subfields and techniques. If you have suggestions for additions or corrections, feel free to reach out!</p>]]></content><author><name></name></author><category term="ML"/><category term="AI"/><category term="reinforcement-learning"/><summary type="html"><![CDATA[This is a little tech tree I've made to understand the landscape of reinforcement learning.]]></summary></entry><entry><title type="html">ROS 2 Essentials</title><link href="https://bobb1ranger.github.io/blog/2025/ROS2essential/" rel="alternate" type="text/html" title="ROS 2 Essentials"/><published>2025-11-23T02:59:00+00:00</published><updated>2025-11-23T02:59:00+00:00</updated><id>https://bobb1ranger.github.io/blog/2025/ROS2essential</id><content type="html" xml:base="https://bobb1ranger.github.io/blog/2025/ROS2essential/"><![CDATA[<p>A quick Recap on why ROS 2 is invented to improve upon ROS.</p> <h1 id="i-why-ros-2">I Why ROS 2</h1> <table> <thead> <tr> <th>Feature</th> <th>ROS</th> <th>ROS 2</th> </tr> </thead> <tbody> <tr> <td>Computational Resources</td> <td>Strong, local resources</td> <td>Potentially limited locally</td> </tr> <tr> <td>Number of Agents</td> <td>Few agents</td> <td>Hundreds of agents</td> </tr> <tr> <td>Network Reliability</td> <td>Stable and reliable</td> <td>Not always reliable</td> </tr> <tr> <td>Application</td> <td>Research-oriented</td> <td>Commercial and industrial use</td> </tr> </tbody> </table> <hr/> <h2 id="1-limitations-of-ros">1. Limitations of ROS:</h2> <ul> <li>ROS is no longer used exclusively for scientific research.</li> <li>More ROS-based products are being commercialized.</li> <li>The increasing variety of application scenarios introduces additional requirements for the system.</li> </ul> <h2 id="2-various-demands-in-the-era-of-intelligent-robotics">2. Various demands in the era of intelligent robotics:</h2> <ul> <li>Streamlined methods for multi-robot systems</li> <li>heterogeneous system compatibility</li> <li>Real-time performance capabilities</li> <li>Robustness to changing network conditions</li> <li>Better suitability for commercial products</li> <li>Lifetime project management</li> </ul> <hr/> <h1 id="ii-main-differences">II Main differences</h1> <h2 id="1-a-revolution-on-architecture">1. A revolution on architecture</h2> <p>In ROS, all nodes are managed by a single node called “Master”. This increases the risk of single point failure. In ROS2, the discovery mechanism based on DDS mitigates the risk.</p> <ul> <li>Date Distribution Service (DDS): A middleware standard that enables real-time, decentralized communication between applications.</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Blogimgs1/ROS1-ROS2-architecture-480.webp 480w,/assets/img/Blogimgs1/ROS1-ROS2-architecture-800.webp 800w,/assets/img/Blogimgs1/ROS1-ROS2-architecture-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/Blogimgs1/ROS1-ROS2-architecture.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The architectures of ROS and ROS 2. </div> <h2 id="2-re-design-of-the-api">2. Re-design of the API</h2> <p>ROS 2 adopts the latest C++ standards and Python 3 while retaining most of the familiar usage patterns.</p> <h2 id="3-build-process-upgrade">3. Build-process Upgrade</h2> <p>In ROS 2, the build process is based on ament and colcon, replacing the older rosbuild and catkin systems used in ROS 1. Ament provides a more modular and extensible build framework, while colcon acts as a higher-level build tool that supports parallel builds, better dependency handling, and cleaner workspace management. Together, they offer a more reliable and scalable workflow, especially for large, multi-package ROS projects.</p>]]></content><author><name></name></author><category term="robotics"/><category term="simulation"/><category term="programming"/><summary type="html"><![CDATA[How ROS 2 is different from ROS.]]></summary></entry><entry><title type="html">Mujoco</title><link href="https://bobb1ranger.github.io/blog/2025/Mujoco_notes/" rel="alternate" type="text/html" title="Mujoco"/><published>2025-11-15T01:14:00+00:00</published><updated>2025-11-15T01:14:00+00:00</updated><id>https://bobb1ranger.github.io/blog/2025/Mujoco_notes</id><content type="html" xml:base="https://bobb1ranger.github.io/blog/2025/Mujoco_notes/"><![CDATA[<h1 id="mujoco-overview">MuJoCo Overview</h1> <p>MuJoCo is a full-featured simulator designed from the ground up for the purpose of <strong>model-based</strong> optimization, and in particular optimization through contacts. Because of its efficiency and high accuracy, MuJoCo makes it possible to evaluate many computationally intensive techniques—such as optimal control, physically consistent state estimation, and system identification—on complex dynamical systems with <strong>contact-rich</strong> behaviors. It also supports more traditional applications, including validating control schemes before deploying them on physical robots, interactive scientific visualization, virtual environments.</p> <p>Key features:</p> <ul> <li>Simulation in generalized coordinates, avoiding joint violations</li> <li>Inverse dynamics that are well-defined <strong>even in the presence of contacts</strong>.</li> <li>Kinematic constraints treatment.</li> <li>Many types of available actuators.</li> <li>Vast options of ODE solvers and integrators.</li> <li>XML model format (called MJCF) and built-in model compiler. Cross-platform GUI in OpenGL.</li> </ul> <h1 id="cmake-and-its-use-in-mujoco">Cmake and its use in MujoCo</h1> <h2 id="what-is-cmake">What is CMake</h2> <p>CMake is a cross-platform build system generator.</p> <ul> <li>reads configuration files (CMakeLists.txt)</li> <li>Detects the system, compilers, dependencies and paths.</li> <li>Generates platform -specific build systems. For example, Makefiles on Linux.</li> </ul> <p>CMake = the tool that prepares the actual build environment, so you can build the same project across many platforms without rewriting build scripts.</p> <h2 id="cmakes-functrelated_posts-false">CMake’s functrelated_posts: false</h2> <ul> <li> <p>“/blog/2025/Mujoco_notes”ion in Mujoco Mujoco uses CMake to configure, build and install its source code. Specifically, CMake handles several things.</p> </li> <li>Building and configuring the Mujoco library. (If we’re using precompiled Mujoco binaries, we don’t need CMake.)</li> <li>Managing dependencies. (GL/GLEW)</li> <li>Cross-platform support.</li> <li>Configuring compile options.</li> <li>Installation and packaging. (Let CMake install headers and libraries to a clean, standard layout.)</li> </ul> <p>Convert Solidworks drawings to MJCF related_posts: false</p> <ul> <li>“/blog/2025/Mujoco_notes”</li> </ul> <h2 id="file-type-and-simulation-building-process">File Type and Simulation Building Process</h2> <h3 id="model-format">Model Format:</h3> <p>.xml type file (Reference: Mujoco official site) Note .xml is super easy to program.</p> <h3 id="compiling">Compiling</h3> <h3 id="visualization-node">Visualization Node</h3> <p>—related_posts: false</p> <ul> <li>“/blog/2025/Mujoco_notes” <h3 id="root-node">Root Node:</h3> <p>Compiler node: used for simulation computations.</p> </li> <li>range of physical variables</li> </ul> <p>Option node: simulation configuration.</p> <ul> <li>Time steps (Default 0.002)</li> <li>Gravity (Exogenous forces)</li> <li>Air drag/ wind environment. Air density and viscousity. (Mujoco is mainly used for multi-body kinetic simulation)</li> <li>Integrator. Euler is quick, RK4(Runge-Kutta) is accurate.</li> <li>solver</li> </ul> <p>The difference between integrator and solver:</p> <ul> <li>The integrator is responsible for numerical time integration of the system’s equations of motion.It uses the current state and computed accelerations/velocities to determine the state at the next time step.</li> <li>The solver is a lower-level component used by the integrator (primarily the semi-implicit Euler variants) to resolve forces and impulses arising from constraints.</li> </ul> <p>Visual node. Lighting conditions and Rendering options. Visual map affects the Mouse interactions. Don’t need to change in most scenarios.</p> <h2 id="resources-allocation">Resources Allocation:</h2> <p>asset: construct by vertices/ .obj/ .stl.</p> <ul> <li>texture. can load .png as texture.</li> <li>Only “skybox” texture can be directly loaded. All other textures should be instead called in materials.</li> <li> <hfield>: Terrain features. Usually, it's loaded from files. </hfield> </li> </ul> <p>Difference between URDF and MJCF:</p>]]></content><author><name></name></author><category term="robotics"/><category term="simulation"/><category term="programming"/><summary type="html"><![CDATA[Some basic features of Mujoco.]]></summary></entry><entry><title type="html">A note on Diffusion Model (Credit Qingyuan Jiang)</title><link href="https://bobb1ranger.github.io/blog/2025/DiffusionModel/" rel="alternate" type="text/html" title="A note on Diffusion Model (Credit Qingyuan Jiang)"/><published>2025-11-11T22:47:00+00:00</published><updated>2025-11-11T22:47:00+00:00</updated><id>https://bobb1ranger.github.io/blog/2025/DiffusionModel</id><content type="html" xml:base="https://bobb1ranger.github.io/blog/2025/DiffusionModel/"><![CDATA[<p>This note is shared with permission from my friend, Qingyuan Jiang.</p> <p>The blog post can be found <a href="https://qingyuan-jiang.github.io/blog/2025/diffusion/">here</a>. You can visit his <a href="https://qingyuan-jiang.github.io/">personal website</a> for more information.</p> <p><em>All credit for the content and ideas in this blog goes to Qingyuan Jiang.</em></p>]]></content><author><name></name></author><category term="AI"/><category term="ML"/><summary type="html"><![CDATA[A Study Note Adapted shared from Qingyuan Jiang's Work.]]></summary></entry><entry><title type="html">Time-domain game interpretation of optimal control</title><link href="https://bobb1ranger.github.io/blog/2025/HinfminmaxGame/" rel="alternate" type="text/html" title="Time-domain game interpretation of optimal control"/><published>2025-11-10T21:06:00+00:00</published><updated>2025-11-10T21:06:00+00:00</updated><id>https://bobb1ranger.github.io/blog/2025/HinfminmaxGame</id><content type="html" xml:base="https://bobb1ranger.github.io/blog/2025/HinfminmaxGame/"><![CDATA[<h1 id="1-the-game-setup">1. The “Game” Setup</h1> <p>We define the <strong>system</strong>, the <strong>players</strong>, and the <strong>rules</strong>.</p> <h2 id="system-dynamics">System Dynamics</h2> \[x_{k+1} = A x_k + B_1 w_k + B_2 u_k.\] <p>We use a standard LQR-like output for simplicity so that \(\|z_k\|_2^2 = x_k^T Q x_k + u_k^T R u_k\):</p> \[z_k = C_1 x_k + D_{12} u_k = \begin{bmatrix} Q^{1/2} x_k \\ R^{1/2} u_k \end{bmatrix}\] <h2 id="players">Players</h2> <ul> <li><strong>Controller</strong> (\(u_k\)): tries to minimize the cost.</li> <li><strong>Disturbance</strong> (\(w_k\)): tries to maximize the cost.</li> </ul> <h2 id="the-games-objective">The Game’s Objective</h2> <p>The \(H_\infty\) goal is to ensure the energy gain is bounded: \(\sum_{k=0}^{\infty} \|z_k\|_2^2 &lt; \gamma^2 \sum_{k=0}^{\infty} \|w_k\|_2^2\). Define:</p> \[J = \sum_{k=0}^{\infty} \left( \|z_k\|_2^2 - \gamma^2 \|w_k\|_2^2 \right)\] <p>This can be rewritten as a <strong>zero-sum game</strong>:</p> <ul> <li>The controller \(u_k\) tries to <strong>minimize</strong> the score.</li> <li>The disturbance \(w_k\) tries to <strong>maximize</strong> it.</li> </ul> <hr/> <h1 id="2-the-scorecard-dynamic-programming">2. The “Scorecard” (Dynamic Programming)</h1> <p>We apply <strong>dynamic programming</strong> to find the “value” of the game.</p> <h2 id="value-function">Value Function</h2> <p>Define the <strong>cost-to-go</strong>:</p> \[V(x_k) = x_k^T P x_k\] <h2 id="bellman-equation">Bellman Equation</h2> \[V(x_k) = \min_{u_k} \max_{w_k} \left\{ \|z_k\|_2^2 - \gamma^2 \|w_k\|_2^2 + V(x_{k+1}) \right\}\] <p>Substitute the known quantities: <span style="color:red">Why the game cost is formulated as a min-max rather than a max-min program?</span></p> <p>When analyzing the discrete-time or continuous-time \(H_\infty\) control problem, the dynamic programming approach leads to a <strong>min–max optimization</strong>: the controller minimizes cost while the disturbance maximizes it.<br/> A natural question is: <em>what happens if we flip the order to max–min?</em></p> <h3 id="1-meaning-of-changing-the-order">1. Meaning of Changing the Order</h3> <ol> <li> <p><strong>Standard formulation (min–max):</strong></p> <p>The controller picks \(u_k\) to minimize the worst-case effect of \(w_k\). This corresponds to the full information control:</p> \[V(x_k) = \min_{u_k} \max_{w_k} \left\{ \ell(x_k,u_k,w_k) + V(x_{k+1}) \right\}.\] </li> <li> <p><strong>Flipped formulation (max–min):</strong></p> <p>The controller must decide first (announce \(u_k\) or even a strategy), and the disturbance reacts after observing it. This means the controller don’t know about the disturbance at current step:</p> \[V(x_k) = \max_{w_k} \min_{u_k} \left\{ \ell(x_k,u_k,w_k) + V(x_{k+1}) \right\}.\] </li> </ol> <p>If the cost function is <strong>convex in \(u\)</strong> and <strong>concave in \(w\)</strong>, then the two formulations are equivalent due to the <em>minimax theorem</em> (saddle point exists). Otherwise, the order matters — typically, the controller is worse off when forced to move first (a Stackelberg-type disadvantage).</p> <h3 id="2-quadratic-stage-cost">2. Quadratic Stage Cost</h3> <p>For the standard (H_\infty) setting, define</p> \[L(u,w) = x^\top Q x + u^\top R u - \gamma^2 w^\top w + (A x + B_1 w + B_2 u)^\top P (A x + B_1 w + B_2 u).\] <p>Here (P) is the value function matrix at the next step in the dynamic programming recursion.</p> <h3 id="3-convexconcave-isaacs-condition">3. Convex–Concave (Isaacs) Condition</h3> <p>Compute the Hessians with respect to \(u\) and \(w\):</p> \[\frac{\partial^2 L}{\partial u^2} = 2(R + B_2^\top P B_2), \qquad \frac{\partial^2 L}{\partial w^2} = -2(\gamma^2 I - B_1^\top P B_1).\] <p>Thus:</p> <ul> <li>\(L\) is <strong>convex in \(u\)</strong> if \(R + B_2^\top P B_2 \succ 0\).</li> <li>\(L\) is concave in \(w\) if \(\gamma^2 I - B_1^\top P B_1 \succ 0\).</li> </ul> <p>This last inequality is the <strong>Isaacs condition</strong> (or the saddle-point condition). When it holds, we can swap the order of optimization:</p> \[\min_u \max_w L(u,w) = \max_w \min_u L(u,w),\] <p>and the \(H_\infty\) Riccati equation derived via dynamic programming remains valid.</p> <h3 id="4-intuitive-interpretation">4. Intuitive Interpretation</h3> <ul> <li> <p>If the Isaacs condition holds, the disturbance’s energy is bounded by \(\gamma\), ensuring that the problem has a well-defined saddle point.<br/> The order of min–max does not matter.</p> </li> <li> <p>If the condition fails, \(L\) is no longer concave in \(w\); the disturbance can exploit the controller’s pre-commitment, and<br/> the <strong>max–min value</strong> (controller as leader) becomes larger — meaning worse performance for the controller.</p> </li> </ul> <p>This is analogous to the <strong>Stackelberg vs. Nash</strong> distinction in game theory.</p> <h3 id="5-practical-check">5. Practical Check</h3> <p>After solving the Riccati or LMI for a given \(\gamma\), test:</p> \[M = \gamma^2 I - B_1^\top P B_1.\] <p>If \(M \succ 0\), then the Isaacs condition holds and<br/> \(\min\max = \max\min\).<br/> If \(M\) has nonpositive eigenvalues, the saddle-point equivalence fails.</p> \[x_k^T P x_k = \min_{u_k} \max_{w_k} \left\{ x_k^T Q x_k + u_k^T R u_k - \gamma^2 w_k^T w_k + x_{k+1}^T P x_{k+1} \right\}\] <hr/> <h1 id="3-solving-the-game-finding-the-moves">3. Solving the Game (finding the moves)</h1> <p>We denote the expression inside as \(L\):</p> \[L = x_k^T Q x_k + u_k^T R u_k - \gamma^2 w_k^T w_k + (A x_k + B_1 w_k + B_2 u_k)^T P (A x_k + B_1 w_k + B_2 u_k)\] <h2 id="step-1-the-disturbances-move-maximize-l">Step 1: The Disturbance’s Move (maximize \(L\))</h2> \[\frac{\partial L}{\partial w_k} = -2\gamma^2 w_k + 2 B_1^T P (A x_k + B_1 w_k + B_2 u_k) = 0\] <p>Solve for \(w_k^*\): \(w_k^* = (\gamma^2 I - B_1^T P B_1)^{-1} B_1^T P (A x_k + B_2 u_k)\)</p> <p><strong>Key insight:</strong><br/> This is the <strong>worst-case disturbance</strong>, dependent on both \(x_k\) and \(u_k\).</p> <hr/> <h2 id="step-2-the-controllers-move-minimize-l">Step 2: The Controller’s Move (minimize \(L\))</h2> <p>\(\frac{\partial L}{\partial u_k} = 2R u_k + 2 B_2^T P (A x_k + B_1 w_k + B_2 u_k) = 0\) Solve for \(u_k^*\): \(u_k^* = -(R + B_2^T P B_2)^{-1} B_2^T P (A x_k + B_1 w_k)\)</p> <p><strong>Problem:</strong> \(u_k^*\) depends on \(w_k\), which is not known in real time.<br/> <strong>Solution:</strong> Assume the controller uses state feedback: \(u_k = -K x_k\) and the disturbance knows this strategy. (This is equivalent to the max-min formulation.)</p> <ul> <li>Note: we still don’t know how this assumption should be changed when \(u_k\) must subject to some strict causality on \(x_k\).</li> </ul> <hr/> <h1 id="4-the-result-the-h_infty-riccati-equation">4. The Result: The \(H_\infty\) Riccati Equation</h1> <p>We plug the worst-case disturbance \(w_k^*\) into \(L\), then find the \(u_k\) minimizing the result.<br/> After algebraic simplification (as in Doyle et al.), the Bellman equation yields the <strong>Discrete-Time Algebraic Riccati Equation (DARE)</strong> for \(H_\infty\) control:</p> \[P = Q + A^T P A - A^T P \begin{bmatrix} B_1 &amp; B_2 \end{bmatrix} \left( R_{H_\infty} + \begin{bmatrix} B_1 &amp; B_2 \end{bmatrix}^T P \begin{bmatrix} B_1 &amp; B_2 \end{bmatrix} \right)^{-1} \begin{bmatrix} B_1 &amp; B_2 \end{bmatrix}^T P A\] <p>where \(R_{H_\infty} = \begin{bmatrix} -\gamma^2 I &amp; 0 \\ 0 &amp; R \end{bmatrix}.\)</p> <hr/> <h1 id="5-lqr-vs-h_infty-a-simple-comparison">5. LQR vs. \(H_\infty\) (a simple comparison)</h1> <table> <thead> <tr> <th style="text-align: center">Control Type</th> <th style="text-align: center">Riccati Equation</th> <th style="text-align: center">Interpretation</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><strong>LQR (H₂)</strong> <br/><br/></td> <td style="text-align: center"><br/>\(P = Q + A^T P A - A^T P B_2 (R + B_2^T P B_2)^{-1} B_2^T P A\)<br/><br/></td> <td style="text-align: center"><br/>Controller minimizes its own cost<br/><br/></td> </tr> <tr> <td style="text-align: center"><strong>\(H_\infty\)</strong> <br/><br/></td> <td style="text-align: center"><br/>\(P = Q + A^T P A - A^T P B_{\text{all}} R_{\text{all}}^{-1} B_{\text{all}}^T P A\)<br/><br/></td> <td style="text-align: center"><br/>Controller competes with disturbance (B_1 w)<br/><br/></td> </tr> </tbody> </table> <p>Here, \(B_{\text{all}}\) and \(R_{\text{all}}\) combine the control and disturbance effects:</p> \[B_{\text{all}} = [B_1 \; B_2], \quad R_{\text{all}} = \begin{bmatrix} -\gamma^2 I &amp; 0 \\ 0 &amp; R \end{bmatrix}\] <p>If there is \(Y\) and \(X\succ 0\) such that the following LMI holds:</p> \[\begin{bmatrix} X &amp; (A X + B_2 Y)^{\top} &amp; B_1^{\top} &amp; (C_1 X + D_{12} Y)^{\top} \\ A X + B_2 Y &amp; X &amp; 0 &amp; 0 \\ B_1 &amp; 0 &amp; \gamma^2 I &amp; 0 \\ C_1 X + D_{12} Y &amp; 0 &amp; 0 &amp; I \end{bmatrix} \succ 0,\] <p>then the following state-feedback control policy \(K = Y X^{-1}\) ensures that \(J &lt; 0\) for all \(w \in \ell_2\), i.e. \(\|T_{zw}\|_\infty&lt; \gamma\).</p> <hr/> <h2 id="interpretation">Interpretation</h2> <ul> <li>The \(-\gamma^2 I\) term acts as a <strong>negative cost</strong>, representing the <strong>disturbance player’s gain</strong>.</li> <li>The controller must design feedback strong enough to <strong>counteract</strong> it, ensuring that the closed-loop system remains stable.</li> <li>The \(H_\infty\) Riccati equation is just the LQR Riccati equation modified to include the <strong>negative cost</strong> of the maximizing disturbance player, scaled by \(\frac{1}{\gamma^2}\).</li> </ul> <hr/>]]></content><author><name></name></author><category term="control"/><category term="math"/><category term="optimization"/><summary type="html"><![CDATA[A simple, time-domain derivation from the game perspective provides an intuitive understanding of where the $$H_\infty$$ Riccati equation comes from. It's a direct application of dynamic programming, similar to the LQR derivation.]]></summary></entry><entry><title type="html">Semidefinite Programming Quick notes</title><link href="https://bobb1ranger.github.io/blog/2025/SDP/" rel="alternate" type="text/html" title="Semidefinite Programming Quick notes"/><published>2025-11-09T19:12:00+00:00</published><updated>2025-11-09T19:12:00+00:00</updated><id>https://bobb1ranger.github.io/blog/2025/SDP</id><content type="html" xml:base="https://bobb1ranger.github.io/blog/2025/SDP/"><![CDATA[<h1 id="conic-programming">Conic Programming</h1> <p>Conic optimization is a subfield of convex optimization that studies problems consisting of minimizing a convex function over the intersection of an affine subspace and a convex cone.</p> <p><strong><em>convex cone</em></strong>: In linear algebra, a cone—sometimes called a linear cone to distinguish it from other sorts of cones—is a subset of a real vector space that is closed under positive scalar multiplication That is \(C\) is a cone if \(x\in C\) implies \(s x \in C\) for every \(s&gt;0\).</p> <ul> <li>A convex cone is a cone that is also closed under addition, or, equivalently, a subset of a vector space that is closed under linear combinations with positive coefficients. It follows that convex cones are convex sets.</li> <li>The conical hull of a set \(C\) is defined as the smallest convex cone that contains \(C \cup \{0\}\). Therefore, it need not be the smallest cone that contains \(C \cup \{0\}\).</li> </ul> <p>The class of conic optimization problems includes some of the most well known classes of convex optimization problems, namely linear and semidefinite programming.</p> <hr/> <h2 id="definition">Definition</h2> <p>Given a real vector space X, a convex, real-valued function:</p> <p>\(f \colon C \mapsto \mathbb{R}\) defined on a convex cone \(C \subset X\), and an affine subspace \(\cal{H}\) defined by a set of affine constraints \(h_i (x) =0\), a conic optimization problem is to find the point \(x \in C \cap \cal{H}\) for which the number \(f(x)\) is minimized.</p> <ul> <li>Example of \(C\) include the positive orthant \(\mathbb{R}_+^n \colon =\{x \in \mathbb{R}^n \colon x \geq 0\}\), positive semidefinite matrices \(\mathbb{S}_+^n\).</li> <li>Often \(f\) is a linear function, in which case the conic optimization problem reduces to a linear program, a semidefinite program, respectively.</li> </ul> <hr/> <h1 id="semidefinite-programming">Semidefinite Programming</h1> <p><strong>Semidefinite programming (SDP)</strong> is a subfield of mathematical programming concerned with the optimization of a linear objective function (a user-specified function that the user wants to minimize or maximize) over the intersection of <strong>the cone of positive semidefinite matrices</strong> with <strong>an affine space</strong>, i.e., a spectrahedron.</p> <ul> <li>A spectrahedron is a shape that can be represented as a linear matrix inequality.</li> </ul> <hr/> <h2 id="initial-motivation">Initial motivation</h2> <p>In semidefinite programming, we use real-valued vectors and are allowed to take the dot product of vectors with semi-definiteness constraints on matrix variables.</p> \[\min_{x^1, ... , x^n \in \mathbb{R}^n} \sum_{i,j \in [n]} c_{i,j} (x^i \cdot x^j)\] \[\text{subject to } \sum_{i,j \in [n]} a_{i,j,k} (x^i \cdot x^j) \leq b_k \quad \forall k.\] <h2 id="equivalent-formulations">Equivalent formulations</h2> <p>Use the gram matrix of some vectors \(X \colon = [x^i \cdot x^j]\). We can rewrite the mathematical program given in the previous section equivalently as:</p> \[\min_{X\in \mathbb{S}^n} \langle C, X\rangle\] \[\text{subject to } X \succeq \mathbf{0}, \langle A_k, X\rangle \leq b_k \quad \forall k.\] <h2 id="duality-theory">Duality Theory</h2> <p>Analogously to linear programming, given a general SDP of the form</p> \[\min_{X\in \mathbb{S}^n} \langle C, X\rangle\] \[\text{subject to } X \succeq \mathbf{0}, \langle A_k, X\rangle \leq b_k \quad \forall k.\] <p>(The primal problem of P-SDP), we define the dual semidefinite program (D-SDP) as</p> \[\max_{y \in \mathbb{R}^n} b^\top y\] \[\text{subject to } \sum_{i = 1}^m y_i A_i \preceq C.\] <ul> <li>Weak duality always holds, which means any feasible solution to the dual SDP lower-bounds the primal SDP value, and conversely, any feasible solution to the primal SDP upper-bounds the dual SDP value.</li> <li>Strong Duality doens’t hold always, which differs from the LP(linear programming). A sufficient condition for strong duality is the <strong>Slater’s condition</strong>.</li> </ul> <h2 id="algorithms-to-solve-sdp">Algorithms to solve SDP</h2>]]></content><author><name></name></author><category term="optimization-lectures"/><category term="math"/><category term="vector_space"/><category term="optimization"/><summary type="html"><![CDATA[a quick note of related math preliminaries on the semidefinite programming]]></summary></entry><entry><title type="html">Lecture note - Inexact Fixed-Point Iterations for Min-Max Problems</title><link href="https://bobb1ranger.github.io/blog/2025/Stephen-Wright-Talk/" rel="alternate" type="text/html" title="Lecture note - Inexact Fixed-Point Iterations for Min-Max Problems"/><published>2025-10-24T20:30:00+00:00</published><updated>2025-10-24T20:30:00+00:00</updated><id>https://bobb1ranger.github.io/blog/2025/Stephen-Wright-Talk</id><content type="html" xml:base="https://bobb1ranger.github.io/blog/2025/Stephen-Wright-Talk/"><![CDATA[<p>I really enjoyed this insightful talk and the speaker’s style of giving lectures.</p> <p>Disclaimer: This is a summary of Stephen Wright’s talk at University of Minnesota on October 24, 2025. The summary was prepared by an attendee and may not capture all details accurately. For complete understanding, please refer to the original <a href="https://arxiv.org/abs/2402.05071">work</a> or contact the <a href="https://wrightstephen.github.io/sw_proj//">speaker</a>. This note is still under work.</p> <h1 id="abstract">Abstract:</h1> <p>We consider constrained, L-smooth, nonconvex-nonconcave min-max problems either satisfying \(\rho\) -cohypomonotonicity or admitting a solution to the \(\rho\)-weakly Minty Variational Inequality (MVI), where larger values of the parameter \(\rho\) &gt; 0 correspond to a greater degree of nonconvexity. Relevant problem classes include two player reinforcement learning and interaction-dominant min-max problems. We proposed inexact variants of Halpern and Krasnoselskii-Mann (KM) iterations and show that they can tolerate more nonconvexity than previously proved. We also provide stochastic algorithms which can tolerate the same amount of nonconvexity. Complexity results are proved in both cases. (Our improvements come from harnessing the recently proposed “conic nonexpansiveness” property of operators.) Finally, we provide a refined analysis for inexact Halpern iteration and propose a stochastic KM iteration with a multilevel Monte Carlo estimator. This talk represents joint work with Ahmet Alacaoglu and Donghwan Kim.</p> <h1 id="introduction">Introduction</h1> <p>Consider the problem</p> \[\begin{equation}\label{eq:minmaxprob} \min_{u\in U} \max_{v \in V} f(u,v) \end{equation}\] <p>where \(U\subseteq \mathbb{R}^m\) and \(V\subseteq \mathbb{R}^n\) are closed convex sets admitting efficient projection operators and \(f:\mathbb{R}^m \times \mathbb{R}^n \mapsto \mathbb{R}\) is a function such that \(\nabla_u f(u,v)\) and \(\nabla_v f(u,v)\) are Lipschitz continuous. The general setting where \(f(u,v)\) can be nonconvex-nonconcave is extremely relevant in machine learning, with applications in generative adversarial networks (GAN).</p> <p>The following non-monotone inclusion (NMI) problem generalizes \eqref{eq:minmaxprob}.</p> \[\text{Find }x^* \in \mathbb{R}^d \text{ such that } 0 \in F(x^*) + G(x^ *),\] <p>where \(F\) is possibly nonmonotone but \(L\)-Lipschitz and \(G: \mathbb{R}^d \rightrightarrows \mathbb{R}^d\) is maximally monotone. Note that we recover Problem \eqref{eq:minmaxprob} by letting:</p> \[x = \begin{bmatrix} u \\ v \end{bmatrix}, \ F(x) = \begin{bmatrix} \nabla_u f(u,v) \\ -\nabla_v f(u,v) \end{bmatrix} \text{ and } G(x) = \begin{bmatrix} \partial{\iota_U} \\ \partial{\iota_V} \end{bmatrix},\] <p>where \(\iota_U\) is the indicator functionfor set \(U\). \(G\) can be understood as simply the subgradient of the convex constraint \(u \in U\) and \(v \in V\). For example, in 1-d case \(U \doteq [0,1]\).</p> \[\iota_U(u) = \begin{cases} 0, &amp; u \in U \\ +\infty, &amp; u \notin U\\ \end{cases}, \text{ and } \partial{\iota_U(u)} = \begin{cases} \{0\}, &amp; u \in (0,1) \\ (-\infty,0], &amp; u = 0\\ [0,\infty), &amp; u = 1\\ \emptyset, &amp; u \notin U \end{cases}.\] <p>The main assumption made is that \(F + G\) is \(\rho\)-cohypomonotone.</p> <h1 id="preliminaries">Preliminaries</h1> <h2 id="mvi-condition-and-weak-mvi">MVI condition and Weak MVI:</h2> <p>The Minty Variational Inequality (MVI) condition states that there exists a solution \(x^*\) such that</p> <ul> <li>Minmax is a special case of NMI</li> <li>Weak MVI holds for y =x*</li> </ul> <h2 id="resolvent">Resolvent:</h2> <p>Resolvent of an operator \(H: \mathbb{R}^d \rightrightarrows \mathbb{R}^d\) is defined as \(J_H := (I + H)^{-1}\).</p> <h2 id="non-expansive-operators">Non-expansive operators</h2> <p>Construct firmly non-expansive operator from non-expansive operator</p> <hr/> <h1 id="algorithm">Algorithm</h1> <h2 id="1-restate-as-a-fixed-point-problem">(1) Restate as a fixed-point problem</h2> <p>\(0 \in (F +G)(x^*)\) is equivalent to</p> \[\begin{align} &amp; x^* = J_{\eta(F + G)}(x^*) = (I + \eta (F + G))^{-1} (x^*) \\ \text{or } &amp; x^* = (1- \alpha) x^* + \alpha J_{\eta(F + G)}(x^*)\\ \end{align}\] <h2 id="2-outer-loop">(2) Outer Loop</h2> <p>Apply a fixed-point iteration (KM or Halpern) that allows for <strong>inexact</strong> evaluation of the resolvent.</p> <ul> <li>Inexactness: \(\|\tilde{J}_{\eta(F + G)} (x_k) - J_{\eta(F + G)} (x_k)\|^2 \leq \epsilon_k^2\). Choice of \(\epsilon_k\) is crucial.</li> <li>Halpern: \(x_{k+1} = \beta_k x_0 + (1-\beta_k)((1- \alpha) x_k + \alpha \tilde{J}_{\eta(F + G)}(x_k))\)</li> <li>KM: \(x_{k+1} = \beta_k x_k + (1-\beta_k)\tilde{J}_{\eta(F + G)}(x_k)\).</li> </ul> <h2 id="3-inner-loop">(3) Inner Loop</h2> <p>Use an optimal first-order algorithm to calculate \(\tilde{J}_{\eta(F + G)}(x_k)\), choosing \(\eta\) to ensure that this subproblem is strongly convex- strongly concave. (Stochastic) extragradient can solve this problem with optimal first-order complexity.</p> <h3 id="details">Details:</h3> <ul> <li>Sublinear convergence rate when there is no exact gradient</li> <li>FBF Forward-Backward-Forward Algorithm</li> </ul> <p>Stochastic Access F via an unbiased oracle Fhat</p> <p>Solve z \in (I _eta(F+G))(z) J \etaF = ( I + \eta F)^(-1) (u,v) = Argmin max f(u’ , v’) + ½\eta (u’ - u)^2 - ½\eta(v’-v)^2</p>]]></content><author><name></name></author><category term="optimization-lectures"/><category term="math"/><category term="convex_optimization"/><category term="duality"/><summary type="html"><![CDATA[Keypoints from Stephen Wright's Talk at University of Minnesota]]></summary></entry><entry><title type="html">Large Models and Training Knowledge Points</title><link href="https://bobb1ranger.github.io/blog/2025/Notes-Transformer/" rel="alternate" type="text/html" title="Large Models and Training Knowledge Points"/><published>2025-10-23T22:30:00+00:00</published><updated>2025-10-23T22:30:00+00:00</updated><id>https://bobb1ranger.github.io/blog/2025/Notes-Transformer</id><content type="html" xml:base="https://bobb1ranger.github.io/blog/2025/Notes-Transformer/"><![CDATA[<p><a href="/assets/pdf/Transformer_Notes.pdf">Open PDF</a></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Transformer_1-480.webp 480w,/assets/img/Transformer_1-800.webp 800w,/assets/img/Transformer_1-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/Transformer_1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> The transformer architecture. </div> <h1 id="1-model-principles"><strong>1. Model Principles</strong></h1> <h2 id="11-transformer"><strong>1.1 Transformer</strong></h2> <h3 id="architecture-overview">Architecture Overview</h3> <p>The Transformer consists of an <strong>Encoder–Decoder</strong> structure, primarily composed of the following modules:</p> <ul> <li><strong>Encoder:</strong> <ul> <li>Multi-head self-attention mechanism</li> <li>Feedforward neural network</li> <li>Layer normalization</li> <li>Residual connection</li> </ul> </li> <li><strong>Decoder:</strong> <ul> <li>Masked multi-head self-attention</li> <li>Encoder–decoder attention</li> <li>Feedforward neural network</li> </ul> </li> </ul> <h3 id="encoder">Encoder</h3> <p><strong>Functional overview of each component:</strong></p> <ul> <li> <p><strong>Positional Encoding</strong> – absolute or relative position encoding enables sequence modeling. It maps the semantic and positional information of tokens into the <strong>same vector space</strong>, allowing self-attention to jointly process both types of information. This makes the attention mechanism directly exploit their joint similarity while keeping parameter count constant and improving training efficiency.<br/> \(z_i = x_i + p_i\)<br/> Here, \(x_i\) encodes semantic meaning and \(p_i\) encodes positional information.</p> </li> <li> <p><strong>Multi-head attention</strong> – the Multi-Head mechanism improves representational capacity by splitting parameters into multiple attention heads, allowing parallel feature extraction.</p> </li> <li><strong>Feedforward neural network (FNN)</strong> – applied after the attention mechanism to independently transform each token representation through nonlinear mappings:<br/> \(\text{FNN}(x) = W_2 \, \text{ReLU}(W_1 x + b_1) + b_2\) Example dimensions: \(d_{\text{model}} = 512\), \(d_{\text{ff}} = 2048\).<br/> For each token: <ul> <li> \[W_1: (2048 \times 512)\] </li> <li>\(W_2: (512 \times 2048)\)<br/> Used for:<br/> (a) learning nonlinear mappings,<br/> (b) extracting per-position features,<br/> (c) expanding and compressing feature space to enhance expressivity.</li> </ul> </li> <li> <p><strong>Layer normalization</strong></p> </li> <li><strong>Residual connection</strong></li> </ul> <h3 id="decoder">Decoder</h3> <p>The decoder has a similar structure to the encoder but introduces <strong>an extra attention layer</strong> to connect with encoder outputs.</p> <ol> <li> <p><strong>Masked multi-head self-attention:</strong><br/> Since text is generated sequentially, the model must satisfy the <strong>causal constraint</strong> — each token can only depend on previous tokens.<br/> This is achieved by masking future positions in the attention weights, enforcing <strong>auto-regressive generation</strong>.</p> </li> <li> <p><strong>Encoder–decoder attention:</strong><br/> Acts as a bridge between the <strong>encoder’s contextual representation</strong> and the <strong>decoder’s generated output</strong>.</p> <ul> <li><strong>Query (Q):</strong> from the decoder (currently generated sequence).</li> <li><strong>Key (K), Value (V):</strong> from the encoder (semantic representation of the input).</li> </ul> </li> </ol> <hr/> <h2 id="12-attention-mechanism"><strong>1.2 Attention Mechanism</strong></h2> <p><strong>Advantages:</strong></p> <ul> <li>Captures long-range dependencies (no vanishing gradient as in RNNs).</li> <li>Enables parallel computation (tokens processed independently).</li> <li>Attention weights are interpretable and visualizable.</li> <li>Handles variable-length input sequences.</li> </ul> <hr/> <h3 id="mathematical-foundation-qkv-matrices--softmax-normalization">Mathematical foundation (Q–K–V matrices + softmax normalization)</h3> <h4 id="qkv-matrix-computation">QKV Matrix Computation</h4> <p>Each input token is linearly projected to obtain Query (Q), Key (K), and Value (V):</p> \[Q = X W_Q, \quad K = X W_K, \quad V = X W_V\] <p>where<br/> \(X \in \mathbb{R}^{n \times d_{\text{model}}}\) \(n\) = sequence length, \(d_{\text{model}}\) = embedding dimension.</p> <ul> <li>\(W_{Q}\), \(W_{K}\), \(W_{V}\) are trainable projection matrices.</li> <li>\(d_k\) = attention dimension, usually set as \(d_k = \frac{d_{\text{model}}}{h}\).</li> </ul> <hr/> <h3 id="self-attention-mechanism">Self-Attention Mechanism</h3> <p>Compute attention weights as scaled dot-products between queries and keys, then use them to weight values:</p> \[\text{Attention}(Q, K, V) = \text{softmax}\!\left(\frac{QK^\top}{\sqrt{d_k}}\right) V\] <p>The scaling factor \(\sqrt{d_k}\) prevents gradient vanishing/exploding during training.</p> <hr/> <h3 id="multi-head-attention">Multi-Head Attention</h3> \[\text{MultiHead}(Q, K, V) = \text{Concat}(\text{head}_1, \dots, \text{head}_h) W_O\] <p>where each head is: \(\text{head}_i = \text{Attention}(Q W_i^Q, K W_i^K, V W_i^V)\)</p> <ul> <li>\(h\): number of heads</li> <li>Each head has independent learnable matrices \(W_i^Q\), \(W_i^K\), \(W_i^V\).</li> <li>Outputs are concatenated and projected to \(d_{\text{model}}\).</li> <li>This allows the model to attend to different representation subspaces and features simultaneously.</li> </ul> <hr/> <h3 id="masked-self-attention">Masked Self-Attention</h3> <p>Used during generation to prevent tokens from attending to future positions:</p> \[\text{MaskedAttention}(Q, K, V) = \text{softmax}\!\left(\frac{QK^\top}{\sqrt{d_k}} + M\right)V\] <p>where the mask matrix \(M = [M_{ij}]\) satisfies: \(M_{ij} = \begin{cases} 0, &amp; i \ge j \\ -\infty, &amp; i &lt; j \end{cases}\)</p> <p>This ensures causal, left-to-right generation.</p> <hr/> <h1 id="2-bert-gpt-t5-architectures"><strong>2. BERT, GPT, T5 architectures</strong></h1> <p>Pretrained language models based on Transformers have achieved major breakthroughs in the field of natural language processing (NLP). Architecture Categories:</p> <ul> <li>Encoder models: contain only the encoder component; suitable for extracting contextual representations (e.g., BERT).</li> <li>Decoder models: contain only the decoder component; suitable for autoregressive generation tasks (e.g., GPT).</li> <li>Encoder–Decoder models: combine both components; suitable for sequence-to-sequence tasks (e.g., T5).</li> </ul> <h2 id="bert-bidirectional-encoder-representation-from-transformers">BERT: Bidirectional Encoder Representation from Transformers</h2> <ol> <li><strong>Encoder-only architecture</strong> — uses only Transformer encoder layers.</li> <li><strong>Pretraining process:</strong> conducted through unsupervised learning, using <strong>Masked Language Modeling (MLM)</strong> and <strong>Next Sentence Prediction (NSP)</strong> tasks. <ul> <li><strong>Masked Language Model (MLM):</strong> randomly masks certain words in the input text, and the model must predict the masked words.</li> <li><strong>Next Sentence Prediction (NSP):</strong> trains the model to determine whether two given sentences are consecutive in the original text, improving contextual understanding.</li> </ul> </li> <li><strong>Fine-tuning process:</strong> adapts the pretrained model to specific downstream tasks (e.g., text classification, QA).</li> </ol> <h2 id="gpt-generative-pretrained-transformer">GPT: Generative Pretrained Transformer</h2> <ol> <li><strong>Decoder-only architecture</strong> — uses a unidirectional autoregressive model composed solely of decoder layers.</li> <li><strong>Pretraining:</strong> uses the <strong>Causal Language Modeling (CLM)</strong> task — predicting the next token based on all preceding tokens.</li> <li><strong>Fine-tuning:</strong> primarily used for text generation tasks, such as dialogue generation and summarization.</li> </ol> <h2 id="t5-text-to-text-transfer-transformer">T5: Text-to-Text Transfer Transformer</h2> <ol> <li><strong>Full Encoder–Decoder architecture.</strong></li> <li><strong>Pretraining:</strong> <ul> <li><strong>Text infilling:</strong> similar to BERT’s MLM but can mask multiple consecutive tokens.</li> <li><strong>Denoising:</strong> randomly deletes segments or words in the input text, and the model must reconstruct the original text.</li> </ul> </li> <li><strong>Fine-tuning:</strong> applicable to a wide variety of text generation tasks, including summarization, translation, and text classification.</li> </ol> <hr/> <h1 id="3-pretraining"><strong>3. Pretraining</strong></h1> <p>Pretraining refers to learning language patterns on large-scale raw corpora (typically internet-scale data) through self-supervised tasks (e.g., next-word prediction or Masked LM). Its goal is to equip the model with general language understanding and generation capabilities, rather than solving a specific task.</p> <h2 id="data-scale-from-millions-to-trillions-of-tokens">Data Scale: From Millions to Trillions of Tokens</h2> <p>The amount of data required for pretraining mainly depends on the model size (number of parameters).<br/> Empirical rules come from the Scaling Laws (Kaplan et al., 2020): the larger the model, the more training tokens are needed in proportion; otherwise, the model becomes undertrained.</p> <table> <thead> <tr> <th>Model Size</th> <th>Representative Model</th> <th>Training Tokens (Empirical)</th> <th>Estimated Data Volume</th> </tr> </thead> <tbody> <tr> <td>~100M params</td> <td>Small language models (e.g., DistilGPT)</td> <td>10⁹ (1B)</td> <td>Tens of GB</td> </tr> <tr> <td>~1B params</td> <td>GPT-2 Small</td> <td>10¹⁰ (10B)</td> <td>Hundreds of GB</td> </tr> <tr> <td>~6B params</td> <td>GPT-J / GPT-NeoX</td> <td>10¹¹ (100B)</td> <td>TB scale</td> </tr> <tr> <td>~70B params</td> <td>LLaMA-2 / Falcon-70B</td> <td>2×10¹² (2T)</td> <td>Tens of TB</td> </tr> <tr> <td>~1T params</td> <td>GPT-4 level</td> <td>10¹³ (10T)</td> <td>Hundreds of TB</td> </tr> </tbody> </table> <ul> <li><strong>Empirical ratio rule:</strong> Ideal training tokens ≈ <strong>20×number of parameters (in tokens)</strong>. For example, a 70B model should ideally be trained on ~1.4T tokens.</li> </ul> <h2 id="training-time">Training Time</h2> <p>Assuming we use A100 GPUs (80GB) or H100 GPUs (80GB):</p> <table> <thead> <tr> <th>Model</th> <th>GPU Type</th> <th>Number of GPUs</th> <th>Data Volume (Tokens)</th> <th>Estimated Training Time</th> </tr> </thead> <tbody> <tr> <td>GPT-2 (1.5B)</td> <td>V100 × 32</td> <td>32 GPUs</td> <td>40B</td> <td>~1 week</td> </tr> <tr> <td>GPT-J (6B)</td> <td>A100 × 64</td> <td>64 GPUs</td> <td>400B</td> <td>~2-3 weeks</td> </tr> <tr> <td>LLaMA-2 70B</td> <td>A100 × 2048</td> <td>2048 GPUs</td> <td>2T</td> <td>~3-4 weeks</td> </tr> <tr> <td>GPT-4 level</td> <td>H100 × 10,000+</td> <td>Tens of thousands</td> <td>10T</td> <td>Several months</td> </tr> </tbody> </table> <h2 id="data-preparation-workload">Data Preparation Workload</h2> <p>Pretraining corpora usually come from a mix of sources:</p> <table> <thead> <tr> <th>Data Type</th> <th>Proportion</th> <th>Source</th> <th>Purpose</th> </tr> </thead> <tbody> <tr> <td>Web Text</td> <td>50-70%</td> <td>Common Crawl, Wikipedia</td> <td>Language diversity</td> </tr> <tr> <td>Books / Papers</td> <td>10-20%</td> <td>BooksCorpus, ArXiv</td> <td>Long context, logic</td> </tr> <tr> <td>Code</td> <td>10-20%</td> <td>GitHub, StackOverflow</td> <td>Program understanding</td> </tr> <tr> <td>Dialogue / QA</td> <td>5-10%</td> <td>OpenAssistant, Reddit</td> <td>Interactive structure</td> </tr> </tbody> </table> <p>Data cleaning often takes more time than training itself. These steps include:</p> <ul> <li>Deduplication</li> <li>Language detection</li> <li>Spam filtering</li> <li>Text normalization (tokenize, normalize)</li> </ul> <hr/> <h1 id="4-fine-tuning-and-instruction-alignment"><strong>4. Fine-Tuning and Instruction Alignment</strong></h1> <h2 id="41--sft-supervised-fine-tuning-and-continued-pretraining">4.1 SFT (Supervised Fine-Tuning) and Continued Pretraining</h2> <p><strong>Supervised Fine-Tuning (SFT)</strong> adapts a pretrained model to a specific task using labeled data or instruction-response pairs.</p> <h3 id="step-1--define-tasks-and-instructions">Step 1 – Define Tasks and Instructions</h3> <ul> <li><strong>Task definition:</strong> specify what the model should do (e.g., text classification, summarization, translation).</li> <li><strong>Instruction design:</strong> build prompt templates such as<br/> <em>“Classify the following text as positive or negative.”</em></li> </ul> <h3 id="step-2--collect-raw-data">Step 2 – Collect Raw Data</h3> <ul> <li>Use public datasets, domain-specific corpora, or crowdsourcing.</li> <li>Clean and normalize data (remove duplicates, fix encoding, etc.).</li> </ul> <h3 id="step-3--label-data">Step 3 – Label Data</h3> <ul> <li>Establish clear annotation rules for consistency.</li> <li>Apply human labeling or semi-automatic labeling tools.</li> </ul> <h3 id="step-4--construct-instruction-dataset">Step 4 – Construct Instruction Dataset</h3> <ul> <li>Split data into training / validation / test sets.</li> <li>Store in structured formats (JSON, CSV, etc.).</li> </ul> <h3 id="step-5--enhance-data-diversity">Step 5 – Enhance Data Diversity</h3> <ul> <li>Use synonym replacement or paraphrasing for augmentation.</li> <li>Cover multiple use-case scenarios.</li> </ul> <h3 id="step-6--evaluate-and-iterate">Step 6 – Evaluate and Iterate</h3> <ul> <li>Run small-scale evaluation to check performance.</li> <li>Refine prompts or add examples for better alignment.</li> </ul> <blockquote> <p>⚠ SFT may cause <strong>over-specialization</strong>—the model can lose generality and exploratory ability.<br/> A common remedy: mix <strong>instruction + pretraining data</strong>, and follow SFT with preference optimization (DPO / PPO / ORPO).</p> </blockquote> <hr/>]]></content><author><name></name></author><category term="LLM"/><category term="AI"/><category term="math"/><summary type="html"><![CDATA[A quick note on Transformer Model]]></summary></entry><entry><title type="html">Normed Vector Space</title><link href="https://bobb1ranger.github.io/blog/2025/Vector-Optimization/" rel="alternate" type="text/html" title="Normed Vector Space"/><published>2025-04-05T05:41:00+00:00</published><updated>2025-04-05T05:41:00+00:00</updated><id>https://bobb1ranger.github.io/blog/2025/Vector-Optimization</id><content type="html" xml:base="https://bobb1ranger.github.io/blog/2025/Vector-Optimization/"><![CDATA[<p>Given a complex-valued \(m \times n\) matrix \(A\), \(A^H\) denotes its hermitian conjugate. \(\ell_2^{m\times n}[Z]\) denotes the Hilbert space of sequences of \(m\times n\) complex-valued matrices, with inner product defined as</p> \[\langle H,G\rangle = \sum_{k=-\infty}^{\infty} \mathrm{trace}(G^H[k]H[k]).\] <p>The \(\ell_2^{m\times n}[Z]\) space can be decomposed as the direct sum of two spaces of sequences \(\ell_2^{m\times n}[Z^+] \oplus \ell_2^{m\times n}[Z^-]\) . The unilateral z-transform of \(G\in \ell_2^{m\times n}[Z+]\) is \(\hat{G}(z) = \sum_{k=0}^\infty G[k] z^{-k}\)</p> <p>\({\mathcal{H}_2^{m \times n}}^\perp\) is the set of functions \(\hat{G} : \mathbb{C} \to \mathbb{C}^{m \times n}\) such that</p> \[\frac{1}{2\pi j} \oint_{\mathcal{C}} \hat{G}(z) z^{n-1} \, dz = \mathbf{0}, \quad \forall n \geq 0\] <p>There is a unique decomposition into \(\mathcal{H}_2\) and \(\mathcal{H}_2^\perp\) for all matrix-valued functions analytic on the unit circle, by the Projection Theorem.</p> <p>\(\mathcal{RH}_2\) and \(\mathcal{RH}_2^\perp\) respectively denote the rational proper transfer function matrices in \(\mathcal{H}_2\) and \(\mathcal{H}_2^\perp\).</p>]]></content><author><name></name></author><category term="optimization-lectures"/><category term="math"/><category term="vector_space"/><category term="optimization"/><category term="duality"/><summary type="html"><![CDATA[a quick note from David Luenberger's book "Optimization by Vector Space Methods"]]></summary></entry><entry><title type="html">a distill-style blog post</title><link href="https://bobb1ranger.github.io/blog/2021/distill/" rel="alternate" type="text/html" title="a distill-style blog post"/><published>2021-05-22T00:00:00+00:00</published><updated>2021-05-22T00:00:00+00:00</updated><id>https://bobb1ranger.github.io/blog/2021/distill</id><content type="html" xml:base="https://bobb1ranger.github.io/blog/2021/distill/"><![CDATA[<h2 id="equations">Equations</h2> <p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/">MathJax 3</a> engine. You just need to surround your math expression with <code class="language-plaintext highlighter-rouge">$$</code>, like <code class="language-plaintext highlighter-rouge">$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>In fact, you can also use a single dollar sign <code class="language-plaintext highlighter-rouge">$</code> to create inline formulas, such as <code class="language-plaintext highlighter-rouge">$ E = mc^2 $</code>, which will render as $ E = mc^2 $. This approach provides the same effect during TeX-based compilation, but visually it appears slightly less bold compared to double-dollar signs <code class="language-plaintext highlighter-rouge">$$</code>, making it blend more naturally with surrounding text.</p> <p>To use display mode, again surround your expression with <code class="language-plaintext highlighter-rouge">$$</code> and place it as a separate paragraph. Here is an example:</p> \[\left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right)\] <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php">on par with KaTeX</a>.</p> <hr/> <h2 id="citations">Citations</h2> <p>Citations are then used in the article body with the <code class="language-plaintext highlighter-rouge">&lt;d-cite&gt;</code> tag. The key attribute is a reference to the id provided in the bibliography. The key attribute can take multiple ids, separated by commas.</p> <p>The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover). If you have an appendix, a bibliography is automatically created and populated in it.</p> <p>Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover. However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well — the authors are human and it’s nice for them to have the community associate them with their work.</p> <hr/> <h2 id="footnotes">Footnotes</h2> <p>Just wrap the text you would like to show up in a footnote in a <code class="language-plaintext highlighter-rouge">&lt;d-footnote&gt;</code> tag. The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote></p> <hr/> <h2 id="code-blocks">Code Blocks</h2> <p>Syntax highlighting is provided within <code class="language-plaintext highlighter-rouge">&lt;d-code&gt;</code> tags. An example of inline code snippets: <code class="language-plaintext highlighter-rouge">&lt;d-code language="html"&gt;let x = 10;&lt;/d-code&gt;</code>. For larger blocks of code, add a <code class="language-plaintext highlighter-rouge">block</code> attribute:</p> <d-code block="" language="javascript"> var x = 25; function(x) { return x * x; } </d-code> <p><strong>Note:</strong> <code class="language-plaintext highlighter-rouge">&lt;d-code&gt;</code> blocks do not look good in the dark mode. You can always use the default code-highlight using the <code class="language-plaintext highlighter-rouge">highlight</code> liquid tag:</p> <figure class="highlight"><pre><code class="language-javascript" data-lang="javascript"><span class="kd">var</span> <span class="nx">x</span> <span class="o">=</span> <span class="mi">25</span><span class="p">;</span>
<span class="kd">function</span><span class="p">(</span><span class="nx">x</span><span class="p">)</span> <span class="p">{</span>
<span class="k">return</span> <span class="nx">x</span> <span class="err">\</span><span class="o">*</span> <span class="nx">x</span><span class="p">;</span>
<span class="p">}</span></code></pre></figure> <hr/> <h2 id="interactive-plots">Interactive Plots</h2> <p>You can add interative plots using plotly + iframes :framed_picture:</p> <div class="l-page"> <iframe src="/assets/plotly/demo.html" frameborder="0" scrolling="no" height="500px" width="100%" style="border: 1px dashed grey;"></iframe> </div> <p>The plot must be generated separately and saved into an HTML file. To generate the plot that you see above, you can use the following code snippet:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">plotly.express</span> <span class="k">as</span> <span class="n">px</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span>
<span class="sh">'</span><span class="s">https://raw.githubusercontent.com/plotly/datasets/master/earthquakes-23k.csv</span><span class="sh">'</span>
<span class="p">)</span>
<span class="n">fig</span> <span class="o">=</span> <span class="n">px</span><span class="p">.</span><span class="nf">density_mapbox</span><span class="p">(</span>
<span class="n">df</span><span class="p">,</span>
<span class="n">lat</span><span class="o">=</span><span class="sh">'</span><span class="s">Latitude</span><span class="sh">'</span><span class="p">,</span>
<span class="n">lon</span><span class="o">=</span><span class="sh">'</span><span class="s">Longitude</span><span class="sh">'</span><span class="p">,</span>
<span class="n">z</span><span class="o">=</span><span class="sh">'</span><span class="s">Magnitude</span><span class="sh">'</span><span class="p">,</span>
<span class="n">radius</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="n">center</span><span class="o">=</span><span class="nf">dict</span><span class="p">(</span><span class="n">lat</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">lon</span><span class="o">=</span><span class="mi">180</span><span class="p">),</span>
<span class="n">zoom</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
<span class="n">mapbox_style</span><span class="o">=</span><span class="sh">"</span><span class="s">stamen-terrain</span><span class="sh">"</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="nf">write_html</span><span class="p">(</span><span class="sh">'</span><span class="s">assets/plotly/demo.html</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <hr/> <h2 id="details-boxes">Details boxes</h2> <p>Details boxes are collapsible boxes which hide additional information from the user. They can be added with the <code class="language-plaintext highlighter-rouge">details</code> liquid tag:</p> <details><summary>Click here to know more</summary> <p>Additional details, where math \(2x - 1\) and <code class="language-plaintext highlighter-rouge">code</code> is rendered correctly.</p> </details> <hr/> <h2 id="mermaid">Mermaid</h2> <p>This theme supports creating diagrams directly in markdown using <a href="https://mermaid.js.org/">Mermaid</a>. Mermaid enables users to render flowcharts, sequence diagrams, class diagrams, Gantt charts, and more. Simply embed the diagram syntax within a mermaid code block.</p> <p>To create a Gantt chart, you can use the following syntax:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">mermaid
</span><span class="sb">gantt
    dateFormat  YYYY-MM-DD
    title A Gantt Diagram

    section Section
    Task A           :a1, 2025-01-01, 30d
    Task B           :after a1, 20d
    Task C           :2025-01-10, 12d</span>
<span class="p">```</span>
</code></pre></div></div> <p>And here’s how it will be rendered:</p> <pre><code class="language-mermaid">gantt
    dateFormat  YYYY-MM-DD
    title A Gantt Diagram

    section Section
    Task A           :a1, 2025-01-01, 30d
    Task B           :after a1, 20d
    Task C           :2025-01-10, 12d
</code></pre> <p>Similarly, you can also use it to create beautiful class diagrams:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>```mermaid
classDiagram
direction LR
    class Animal {
        +String species
        +int age
        +makeSound()
    }
    class Dog {
        +String breed
        +bark()
    }
    class Cat {
        +String color
        +meow()
    }
    class Bird {
        +String wingSpan
        +fly()
    }
    class Owner {
        +String name
        +int age
        +adoptAnimal(Animal animal)
    }

    Animal &lt;|-- Dog
    Animal &lt;|-- Cat
    Animal &lt;|-- Bird
    Owner "1" --&gt; "0..*" Animal

    Dog : +fetch()
    Cat : +purr()
    Bird : +sing()
```
</code></pre></div></div> <p>It will be presented as:</p> <pre><code class="language-mermaid">classDiagram
direction LR
    class Animal {
        +String species
        +int age
        +makeSound()
    }
    class Dog {
        +String breed
        +bark()
    }
    class Cat {
        +String color
        +meow()
    }
    class Bird {
        +String wingSpan
        +fly()
    }
    class Owner {
        +String name
        +int age
        +adoptAnimal(Animal animal)
    }

    Animal &lt;|-- Dog
    Animal &lt;|-- Cat
    Animal &lt;|-- Bird
    Owner "1" --&gt; "0..*" Animal

    Dog : +fetch()
    Cat : +purr()
    Bird : +sing()
</code></pre> <p>With Mermaid, you can easily add clear and dynamic diagrams to enhance your blog content.</p> <hr/> <h2 id="diff2html">Diff2Html</h2> <p>This theme also supports integrating <a href="https://github.com/rtfpessoa/diff2html">Diff2Html</a>, a tool that beautifully renders code differences (diffs) directly in markdown. Diff2Html is ideal for showcasing code changes, allowing you to clearly present additions, deletions, and modifications. It’s perfect for code reviews, documentation, and tutorials where step-by-step code changes need to be highlighted—you can even introduce changes across multiple files at once.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff2html
</span><span class="sb">diff --git a/utils/mathUtils.js b/utils/mathUtils.js
index 3b5f3d1..c7f9b2e 100644
--- a/utils/mathUtils.js
+++ b/utils/mathUtils.js
@@ -1,8 +1,12 @@
-// Basic math utilities
+// Extended math utilities with additional functions

-export function calculateArea(radius) {
-    const PI = 3.14159;
+export function calculateCircleMetrics(radius) {
+    const PI = Math.PI;
     const area = PI * radius ** 2;
+    const circumference = 2 * PI * radius;
+
+    if (!isValidRadius(radius)) throw new Error("Invalid radius");
+
     return { area, circumference };
 }

-export function validateRadius(radius) {
+export function isValidRadius(radius) {
     return typeof radius === 'number' &amp;&amp; radius &gt; 0;
 }

diff --git a/main.js b/main.js
index 5f6a9c3..b7d4e8f 100644
--- a/main.js
+++ b/main.js
@@ -2,9 +2,12 @@
 import { calculateCircleMetrics } from './utils/mathUtils';

-function displayCircleMetrics(radius) {
-    const { area } = calculateCircleMetrics(radius);
+function displayCircleMetrics(radius) {
+    const { area, circumference } = calculateCircleMetrics(radius);
     console.log(`Area: ${area}`);
+    console.log(`Circumference: ${circumference}`);
 }

-displayCircleMetrics(5);
+try {
+    displayCircleMetrics(5);
+} catch (error) {
+    console.error("Error:", error.message);
+}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Here’s how it will look when rendered with Diff2Html:</p> <pre><code class="language-diff2html">diff --git a/utils/mathUtils.js b/utils/mathUtils.js
index 3b5f3d1..c7f9b2e 100644
--- a/utils/mathUtils.js
+++ b/utils/mathUtils.js
@@ -1,8 +1,12 @@
-// Basic math utilities
+// Extended math utilities with additional functions

-export function calculateArea(radius) {
-    const PI = 3.14159;
+export function calculateCircleMetrics(radius) {
+    const PI = Math.PI;
     const area = PI * radius ** 2;
+    const circumference = 2 * PI * radius;
+
+    if (!isValidRadius(radius)) throw new Error("Invalid radius");
+
     return { area, circumference };
 }

-export function validateRadius(radius) {
+export function isValidRadius(radius) {
     return typeof radius === 'number' &amp;&amp; radius &gt; 0;
 }

diff --git a/main.js b/main.js
index 5f6a9c3..b7d4e8f 100644
--- a/main.js
+++ b/main.js
@@ -2,9 +2,12 @@
 import { calculateCircleMetrics } from './utils/mathUtils';

-function displayCircleMetrics(radius) {
-    const { area } = calculateCircleMetrics(radius);
+function displayCircleMetrics(radius) {
+    const { area, circumference } = calculateCircleMetrics(radius);
     console.log(`Area: ${area}`);
+    console.log(`Circumference: ${circumference}`);
 }

-displayCircleMetrics(5);
+try {
+    displayCircleMetrics(5);
+} catch (error) {
+    console.error("Error:", error.message);
+}
</code></pre> <hr/> <h2 id="leaflet">Leaflet</h2> <p><a href="https://leafletjs.com/">Leaflet</a> is created by Ukrainian software engineer <a href="https://agafonkin.com/">Volodymyr Agafonkin</a>, allowing interactive maps to be embedded in webpages. With support for <a href="https://geojson.org/">GeoJSON data</a>, Leaflet allows you to highlight specific regions, making it easy to visualize geographical information in detail.</p> <p>You can use the following code to load map information on <a href="https://www.openstreetmap.org/">OpenStreetMap</a>:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">geojson
</span><span class="sb">{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "properties": {
        "name": "Crimea",
        "popupContent": "Occupied Crimea"
      },
      "geometry": {
        "type": "Polygon",
        "coordinates": [
          [
            [
              33.9,
              45.3
            ],
            [
              36.5,
              45.3
            ],
            [
              36.5,
              44.4
            ],
            [
              33.9,
              44.4
            ],
            [
              33.9,
              45.3
            ]
          ]
        ]
      }
    },
    {
      "type": "Feature",
      "properties": {
        "name": "Donetsk",
        "popupContent": "Occupied Donetsk"
      },
      "geometry": {
        "type": "Polygon",
        "coordinates": [
          [
            [
              37.5,
              48.5
            ],
            [
              39.5,
              48.5
            ],
            [
              39.5,
              47.5
            ],
            [
              37.5,
              47.5
            ],
            [
              37.5,
              48.5
            ]
          ]
        ]
      }
    },
    {
      "type": "Feature",
      "properties": {
        "name": "Luhansk",
        "popupContent": "Occupied Luhansk"
      },
      "geometry": {
        "type": "Polygon",
        "coordinates": [
          [
            [
              38.5,
              49.5
            ],
            [
              40.5,
              49.5
            ],
            [
              40.5,
              48.5
            ],
            [
              38.5,
              48.5
            ],
            [
              38.5,
              49.5
            ]
          ]
        ]
      }
    },
    {
      "type": "Feature",
      "properties": {
        "name": "Kherson",
        "popupContent": "Occupied Kherson"
      },
      "geometry": {
        "type": "Polygon",
        "coordinates": [
          [
            [
              32.3,
              47.3
            ],
            [
              34.3,
              47.3
            ],
            [
              34.3,
              46.3
            ],
            [
              32.3,
              46.3
            ],
            [
              32.3,
              47.3
            ]
          ]
        ]
      }
    },
    {
      "type": "Feature",
      "properties": {
        "name": "Zaporizhzhia",
        "popupContent": "Occupied Zaporizhzhia"
      },
      "geometry": {
        "type": "Polygon",
        "coordinates": [
          [
            [
              34.3,
              48
            ],
            [
              36.3,
              48
            ],
            [
              36.3,
              47
            ],
            [
              34.3,
              47
            ],
            [
              34.3,
              48
            ]
          ]
        ]
      }
    }
  ]
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>The rendered map below highlights the regions of Ukraine that have been illegally occupied by Russia over the years, including Crimea and the four eastern regions:</p> <pre><code class="language-geojson">{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "properties": {
        "name": "Crimea",
        "popupContent": "Occupied Crimea"
      },
      "geometry": {
        "type": "Polygon",
        "coordinates": [
          [
            [
              33.9,
              45.3
            ],
            [
              36.5,
              45.3
            ],
            [
              36.5,
              44.4
            ],
            [
              33.9,
              44.4
            ],
            [
              33.9,
              45.3
            ]
          ]
        ]
      }
    },
    {
      "type": "Feature",
      "properties": {
        "name": "Donetsk",
        "popupContent": "Occupied Donetsk"
      },
      "geometry": {
        "type": "Polygon",
        "coordinates": [
          [
            [
              37.5,
              48.5
            ],
            [
              39.5,
              48.5
            ],
            [
              39.5,
              47.5
            ],
            [
              37.5,
              47.5
            ],
            [
              37.5,
              48.5
            ]
          ]
        ]
      }
    },
    {
      "type": "Feature",
      "properties": {
        "name": "Luhansk",
        "popupContent": "Occupied Luhansk"
      },
      "geometry": {
        "type": "Polygon",
        "coordinates": [
          [
            [
              38.5,
              49.5
            ],
            [
              40.5,
              49.5
            ],
            [
              40.5,
              48.5
            ],
            [
              38.5,
              48.5
            ],
            [
              38.5,
              49.5
            ]
          ]
        ]
      }
    },
    {
      "type": "Feature",
      "properties": {
        "name": "Kherson",
        "popupContent": "Occupied Kherson"
      },
      "geometry": {
        "type": "Polygon",
        "coordinates": [
          [
            [
              32.3,
              47.3
            ],
            [
              34.3,
              47.3
            ],
            [
              34.3,
              46.3
            ],
            [
              32.3,
              46.3
            ],
            [
              32.3,
              47.3
            ]
          ]
        ]
      }
    },
    {
      "type": "Feature",
      "properties": {
        "name": "Zaporizhzhia",
        "popupContent": "Occupied Zaporizhzhia"
      },
      "geometry": {
        "type": "Polygon",
        "coordinates": [
          [
            [
              34.3,
              48
            ],
            [
              36.3,
              48
            ],
            [
              36.3,
              47
            ],
            [
              34.3,
              47
            ],
            [
              34.3,
              48
            ]
          ]
        ]
      }
    }
  ]
}
</code></pre> <hr/> <h2 id="chartjs-echarts-and-vega-lite">Chartjs, Echarts and Vega-Lite</h2> <p><a href="https://www.chartjs.org/">Chart.js</a> is a versatile JavaScript library for creating responsive and interactive charts. Supporting multiple chart types like bar, line, pie, and radar, it’s an ideal tool for visualizing data directly in webpages.</p> <p>Here’s an example of a JSON-style configuration that creates a bar chart in Chart.js:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>```chartjs
{
  "type": "bar",
  "data": {
    "labels": ["2017", "2018", "2019", "2020", "2021"],
    "datasets": [
      {
        "label": "Population (millions)",
        "data": [12, 15, 13, 14, 16],
        "backgroundColor": "rgba(54, 162, 235, 0.6)",
        "borderColor": "rgba(54, 162, 235, 1)",
        "borderWidth": 1
      }
    ]
  },
  "options": {
    "scales": {
      "y": {
        "beginAtZero": true
      }
    }
  }
}
```
</code></pre></div></div> <p>The rendered bar chart illustrates population data from 2017 to 2021:</p> <pre><code class="language-chartjs">{
  "type": "bar",
  "data": {
    "labels": ["2017", "2018", "2019", "2020", "2021"],
    "datasets": [
      {
        "label": "Population (millions)",
        "data": [12, 15, 13, 14, 16],
        "backgroundColor": "rgba(54, 162, 235, 0.6)",
        "borderColor": "rgba(54, 162, 235, 1)",
        "borderWidth": 1
      }
    ]
  },
  "options": {
    "scales": {
      "y": {
        "beginAtZero": true
      }
    }
  }
}
</code></pre> <hr/> <p><a href="https://echarts.apache.org/">ECharts</a> is a powerful visualization library from <a href="https://www.apache.org/">Apache</a> that supports a wide range of interactive charts, including more advanced types such as scatter plots, heatmaps, and geographic maps.</p> <p>The following JSON configuration creates a visually enhanced line chart that displays monthly sales data for two products.</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>```echarts
{
  "title": {
    "text": "Monthly Sales Comparison",
    "left": "center"
  },
  "tooltip": {
    "trigger": "axis",
    "backgroundColor": "rgba(50, 50, 50, 0.7)",
    "borderColor": "#777",
    "borderWidth": 1,
    "textStyle": {
      "color": "#fff"
    }
  },
  "legend": {
    "data": ["Product A", "Product B"],
    "top": "10%"
  },
  "xAxis": {
    "type": "category",
    "data": ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"],
    "axisLine": {
      "lineStyle": {
        "color": "#888"
      }
    }
  },
  "yAxis": {
    "type": "value",
    "axisLine": {
      "lineStyle": {
        "color": "#888"
      }
    },
    "splitLine": {
      "lineStyle": {
        "type": "dashed"
      }
    }
  },
  "series": [
    {
      "name": "Product A",
      "type": "line",
      "smooth": true,
      "data": [820, 932, 901, 934, 1290, 1330, 1320, 1400, 1450, 1500, 1600, 1650],
      "itemStyle": {
        "color": "#5470C6"
      },
      "lineStyle": {
        "width": 3
      },
      "areaStyle": {
        "color": {
          "type": "linear",
          "x": 0,
          "y": 0,
          "x2": 0,
          "y2": 1,
          "colorStops": [
            { "offset": 0, "color": "rgba(84, 112, 198, 0.5)" },
            { "offset": 1, "color": "rgba(84, 112, 198, 0)" }
          ]
        }
      },
      "emphasis": {
        "focus": "series"
      }
    },
    {
      "name": "Product B",
      "type": "line",
      "smooth": true,
      "data": [620, 732, 701, 734, 1090, 1130, 1120, 1200, 1250, 1300, 1400, 1450],
      "itemStyle": {
        "color": "#91CC75"
      },
      "lineStyle": {
        "width": 3
      },
      "areaStyle": {
        "color": {
          "type": "linear",
          "x": 0,
          "y": 0,
          "x2": 0,
          "y2": 1,
          "colorStops": [
            { "offset": 0, "color": "rgba(145, 204, 117, 0.5)" },
            { "offset": 1, "color": "rgba(145, 204, 117, 0)" }
          ]
        }
      },
      "emphasis": {
        "focus": "series"
      }
    }
  ]
}
```
</code></pre></div></div> <p>The rendered output is shown below, and you can also interact with it using your mouse:</p> <pre><code class="language-echarts">{
  "title": {
    "text": "Monthly Sales Comparison",
    "left": "center"
  },
  "tooltip": {
    "trigger": "axis",
    "backgroundColor": "rgba(50, 50, 50, 0.7)",
    "borderColor": "#777",
    "borderWidth": 1,
    "textStyle": {
      "color": "#fff"
    }
  },
  "legend": {
    "data": ["Product A", "Product B"],
    "top": "10%"
  },
  "xAxis": {
    "type": "category",
    "data": ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"],
    "axisLine": {
      "lineStyle": {
        "color": "#888"
      }
    }
  },
  "yAxis": {
    "type": "value",
    "axisLine": {
      "lineStyle": {
        "color": "#888"
      }
    },
    "splitLine": {
      "lineStyle": {
        "type": "dashed"
      }
    }
  },
  "series": [
    {
      "name": "Product A",
      "type": "line",
      "smooth": true,
      "data": [820, 932, 901, 934, 1290, 1330, 1320, 1400, 1450, 1500, 1600, 1650],
      "itemStyle": {
        "color": "#5470C6"
      },
      "lineStyle": {
        "width": 3
      },
      "areaStyle": {
        "color": {
          "type": "linear",
          "x": 0,
          "y": 0,
          "x2": 0,
          "y2": 1,
          "colorStops": [
            { "offset": 0, "color": "rgba(84, 112, 198, 0.5)" },
            { "offset": 1, "color": "rgba(84, 112, 198, 0)" }
          ]
        }
      },
      "emphasis": {
        "focus": "series"
      }
    },
    {
      "name": "Product B",
      "type": "line",
      "smooth": true,
      "data": [620, 732, 701, 734, 1090, 1130, 1120, 1200, 1250, 1300, 1400, 1450],
      "itemStyle": {
        "color": "#91CC75"
      },
      "lineStyle": {
        "width": 3
      },
      "areaStyle": {
        "color": {
          "type": "linear",
          "x": 0,
          "y": 0,
          "x2": 0,
          "y2": 1,
          "colorStops": [
            { "offset": 0, "color": "rgba(145, 204, 117, 0.5)" },
            { "offset": 1, "color": "rgba(145, 204, 117, 0)" }
          ]
        }
      },
      "emphasis": {
        "focus": "series"
      }
    }
  ]
}
</code></pre> <hr/> <p><a href="https://vega.github.io/vega-lite/">Vega-Lite</a> is a declarative visualization grammar that allows users to create, share, and customize a wide range of interactive data visualizations. The following JSON configuration generates a straightforward bar chart:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>```vega_lite
{
  "$schema": "https://vega.github.io/schema/vega/v5.json",
  "width": 400,
  "height": 200,
  "padding": 5,

  "data": [
    {
      "name": "table",
      "values": [
        {"category": "A", "value": 28},
        {"category": "B", "value": 55},
        {"category": "C", "value": 43},
        {"category": "D", "value": 91},
        {"category": "E", "value": 81},
        {"category": "F", "value": 53},
        {"category": "G", "value": 19},
        {"category": "H", "value": 87}
      ]
    }
  ],

  "scales": [
    {
      "name": "xscale",
      "type": "band",
      "domain": {"data": "table", "field": "category"},
      "range": "width",
      "padding": 0.1
    },
    {
      "name": "yscale",
      "type": "linear",
      "domain": {"data": "table", "field": "value"},
      "nice": true,
      "range": "height"
    }
  ],

  "axes": [
    {"orient": "bottom", "scale": "xscale"},
    {"orient": "left", "scale": "yscale"}
  ],

  "marks": [
    {
      "type": "rect",
      "from": {"data": "table"},
      "encode": {
        "enter": {
          "x": {"scale": "xscale", "field": "category"},
          "width": {"scale": "xscale", "band": 0.8},
          "y": {"scale": "yscale", "field": "value"},
          "y2": {"scale": "yscale", "value": 0},
          "fill": {"value": "steelblue"}
        },
        "update": {
          "fillOpacity": {"value": 1}
        },
        "hover": {
          "fill": {"value": "orange"}
        }
      }
    }
  ]
}
```
</code></pre></div></div> <p>The rendered output shows a clean and simple bar chart with a hover effect：</p> <pre><code class="language-vega_lite">{
  "$schema": "https://vega.github.io/schema/vega/v5.json",
  "width": 400,
  "height": 200,
  "padding": 5,

  "data": [
    {
      "name": "table",
      "values": [
        {"category": "A", "value": 28},
        {"category": "B", "value": 55},
        {"category": "C", "value": 43},
        {"category": "D", "value": 91},
        {"category": "E", "value": 81},
        {"category": "F", "value": 53},
        {"category": "G", "value": 19},
        {"category": "H", "value": 87}
      ]
    }
  ],

  "scales": [
    {
      "name": "xscale",
      "type": "band",
      "domain": {"data": "table", "field": "category"},
      "range": "width",
      "padding": 0.1
    },
    {
      "name": "yscale",
      "type": "linear",
      "domain": {"data": "table", "field": "value"},
      "nice": true,
      "range": "height"
    }
  ],

  "axes": [
    {"orient": "bottom", "scale": "xscale"},
    {"orient": "left", "scale": "yscale"}
  ],

  "marks": [
    {
      "type": "rect",
      "from": {"data": "table"},
      "encode": {
        "enter": {
          "x": {"scale": "xscale", "field": "category"},
          "width": {"scale": "xscale", "band": 0.8},
          "y": {"scale": "yscale", "field": "value"},
          "y2": {"scale": "yscale", "value": 0},
          "fill": {"value": "steelblue"}
        },
        "update": {
          "fillOpacity": {"value": 1}
        },
        "hover": {
          "fill": {"value": "orange"}
        }
      }
    }
  ]
}
</code></pre> <hr/> <h2 id="tikz">TikZ</h2> <p><a href="https://tikz.net/">TikZ</a> is a powerful LaTeX-based drawing tool powered by <a href="https://tikzjax.com/">TikZJax</a>. You can easily port TikZ drawings from papers, posters, and notes. For example, we can use the following code to illustrate Euler’s formula $ e^{i \theta} = \cos \theta + i \sin \theta $:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">"text/tikz"</span><span class="nt">&gt;</span>
<span class="se">\b</span>egin{tikzpicture}
    <span class="se">\f</span>illdraw[fill=cyan!10, draw=blue, thick] (0,0) circle (2cm);<span class="sb">

    \draw[-&gt;, thick] (-2.5,0) -- (2.5,0) node[right] {Re};
    \draw[-&gt;, thick] (0,-2.5) -- (0,2.5) node[above] {Im};

    \draw[-&gt;, thick, color=purple] (0,0) -- (1.5,1.5);
    \node[color=purple] at (1.1, 1.7) {$e^{i\theta}$};

    \draw[thick] (0.7,0) arc (0:45:0.7);
    \node at (0.9, 0.3) {$\theta$};

    \draw[dashed, color=gray] (1.5,1.5) -- (1.5,0) node[below, black] {$\cos \theta$};
    \draw[dashed, color=gray] (1.5,1.5) -- (0,1.5) node[left, black] {$\sin \theta$};
    \node at (2.2, 0) [below] {1}; 
    \node at (0, 2.2) [left] {$i$}; 
    \node at (1.5,1.5) [above right, color=blue] {$(\cos \theta \, \sin \theta)$}; 
</span><span class="se">\e</span>nd{tikzpicture}
<span class="nt">&lt;/script&gt;</span>
</code></pre></div></div> <p>The rendered output is shown below, displayed as a vector graphic：</p> <script type="text/tikz">
\begin{tikzpicture}
    \filldraw[fill=cyan!10, draw=blue, thick] (0,0) circle (2cm);

    \draw[->, thick] (-2.5,0) -- (2.5,0) node[right] {Re};
    \draw[->, thick] (0,-2.5) -- (0,2.5) node[above] {Im};

    \draw[->, thick, color=purple] (0,0) -- (1.5,1.5);
    \node[color=purple] at (1.1, 1.7) {$e^{i\theta}$};

    \draw[thick] (0.7,0) arc (0:45:0.7);
    \node at (0.9, 0.3) {$\theta$};

    \draw[dashed, color=gray] (1.5,1.5) -- (1.5,0) node[below, black] {$\cos \theta$};
    \draw[dashed, color=gray] (1.5,1.5) -- (0,1.5) node[left, black] {$\sin \theta$};
    \node at (2.2, 0) [below] {1}; 
    \node at (0, 2.2) [left] {$i$}; 
    \node at (1.5,1.5) [above right, color=blue] {$(\cos \theta \, \sin \theta)$}; 
\end{tikzpicture}
</script> <hr/> <h2 id="typograms">Typograms</h2> <p><a href="https://google.github.io/typograms/">Typograms</a> are a way of combining text and graphics to convey information in a clear and visually engaging manner. Typograms are particularly effective for illustrating simple diagrams, charts, and concept visuals where text and graphics are closely integrated. The following example demonstrates a simple Typogram:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>```typograms
             ___________________
            /                  /|
           /__________________/ |
          |                  |  |
          |     Distill      |  |
          |                  |  |
          |                  | /
          |__________________|/
```
</code></pre></div></div> <p>The rendered output is shown below：</p> <pre><code class="language-typograms">             ___________________
            /                  /|
           /__________________/ |
          |                  |  |
          |     Distill      |  |
          |                  |  |
          |                  | /
          |__________________|/
</code></pre> <hr/> <h2 id="layouts">Layouts</h2> <p>The main text column is referred to as the body. It is the assumed layout of any direct descendants of the <code class="language-plaintext highlighter-rouge">d-article</code> element.</p> <div class="fake-img l-body"> <p>.l-body</p> </div> <p>For images you want to display a little larger, try <code class="language-plaintext highlighter-rouge">.l-page</code>:</p> <div class="fake-img l-page"> <p>.l-page</p> </div> <p>All of these have an outset variant if you want to poke out from the body text a little bit. For instance:</p> <div class="fake-img l-body-outset"> <p>.l-body-outset</p> </div> <div class="fake-img l-page-outset"> <p>.l-page-outset</p> </div> <p>Occasionally you’ll want to use the full browser width. For this, use <code class="language-plaintext highlighter-rouge">.l-screen</code>. You can also inset the element a little from the edge of the browser by using the inset variant.</p> <div class="fake-img l-screen"> <p>.l-screen</p> </div> <div class="fake-img l-screen-inset"> <p>.l-screen-inset</p> </div> <p>The final layout is for marginalia, asides, and footnotes. It does not interrupt the normal flow of <code class="language-plaintext highlighter-rouge">.l-body</code> sized text except on mobile screen sizes.</p> <div class="fake-img l-gutter"> <p>.l-gutter</p> </div> <hr/> <h2 id="other-typography">Other Typography?</h2> <p>Emphasis, aka italics, with <em>asterisks</em> (<code class="language-plaintext highlighter-rouge">*asterisks*</code>) or <em>underscores</em> (<code class="language-plaintext highlighter-rouge">_underscores_</code>).</p> <p>Strong emphasis, aka bold, with <strong>asterisks</strong> or <strong>underscores</strong>.</p> <p>Combined emphasis with <strong>asterisks and <em>underscores</em></strong>.</p> <p>Strikethrough uses two tildes. <del>Scratch this.</del></p> <ol> <li>First ordered list item</li> <li>Another item ⋅⋅* Unordered sub-list.</li> <li>Actual numbers don’t matter, just that it’s a number ⋅⋅1. Ordered sub-list</li> <li>And another item.</li> </ol> <p>⋅⋅⋅You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we’ll use three here to also align the raw Markdown).</p> <p>⋅⋅⋅To have a line break without a paragraph, you will need to use two trailing spaces.⋅⋅ ⋅⋅⋅Note that this line is separate, but within the same paragraph.⋅⋅ ⋅⋅⋅(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)</p> <ul> <li> <p>Unordered list can use asterisks</p> </li> <li> <p>Or minuses</p> </li> <li> <p>Or pluses</p> </li> </ul> <p><a href="https://www.google.com">I’m an inline-style link</a></p> <p><a href="https://www.google.com" title="Google's Homepage">I’m an inline-style link with title</a></p> <p><a href="https://www.mozilla.org">I’m a reference-style link</a></p> <p><a href="http://slashdot.org">You can use numbers for reference-style link definitions</a></p> <p>Or leave it empty and use the <a href="http://www.reddit.com">link text itself</a>.</p> <p>URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or <a href="http://www.example.com">http://www.example.com</a> and sometimes example.com (but not on Github, for example).</p> <p>Some text to show that the reference links can follow later.</p> <p>Here’s our logo (hover to see the title text):</p> <p>Inline-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 1"/></p> <p>Reference-style: <img src="https://github.com/adam-p/markdown-here/raw/master/src/common/images/icon48.png" alt="alt text" title="Logo Title Text 2"/></p> <p>Inline <code class="language-plaintext highlighter-rouge">code</code> has <code class="language-plaintext highlighter-rouge">back-ticks around</code> it.</p> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">s</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">JavaScript syntax highlighting</span><span class="dl">"</span><span class="p">;</span>
<span class="nf">alert</span><span class="p">(</span><span class="nx">s</span><span class="p">);</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">s</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Python syntax highlighting</span><span class="sh">"</span>
<span class="k">print</span> <span class="n">s</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>No language indicated, so no syntax highlighting.
But let's throw in a &lt;b&gt;tag&lt;/b&gt;.
</code></pre></div></div> <p>Colons can be used to align columns.</p> <table> <thead> <tr> <th>Tables</th> <th style="text-align: center">Are</th> <th style="text-align: right">Cool</th> </tr> </thead> <tbody> <tr> <td>col 3 is</td> <td style="text-align: center">right-aligned</td> <td style="text-align: right">$1600</td> </tr> <tr> <td>col 2 is</td> <td style="text-align: center">centered</td> <td style="text-align: right">$12</td> </tr> <tr> <td>zebra stripes</td> <td style="text-align: center">are neat</td> <td style="text-align: right">$1</td> </tr> </tbody> </table> <p>There must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don’t need to make the raw Markdown line up prettily. You can also use inline Markdown.</p> <table> <thead> <tr> <th>Markdown</th> <th>Less</th> <th>Pretty</th> </tr> </thead> <tbody> <tr> <td><em>Still</em></td> <td><code class="language-plaintext highlighter-rouge">renders</code></td> <td><strong>nicely</strong></td> </tr> <tr> <td>1</td> <td>2</td> <td>3</td> </tr> </tbody> </table> <blockquote> <p>Blockquotes are very handy in email to emulate reply text. This line is part of the same quote.</p> </blockquote> <p>Quote break.</p> <blockquote> <p>This is a very long line that will still be quoted properly when it wraps. Oh boy let’s keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can <em>put</em> <strong>Markdown</strong> into a blockquote.</p> </blockquote> <p>Here’s a line for us to start with.</p> <p>This line is separated from the one above by two newlines, so it will be a <em>separate paragraph</em>.</p> <p>This line is also a separate paragraph, but… This line is only separated by a single newline, so it’s a separate line in the <em>same paragraph</em>.</p>]]></content><author><name>Albert Einstein</name></author><category term="distill"/><category term="formatting"/><summary type="html"><![CDATA[an example of a distill-style blog post and main elements]]></summary></entry></feed>